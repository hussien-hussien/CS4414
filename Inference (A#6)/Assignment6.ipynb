{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Write your code in the cells provided.  Where appropirate, enter markdown to answer questions.\n",
    "\n",
    "* Submit this notebook to owl.\n",
    "\n",
    "`TODO`:\n",
    "* Part C & D??\n",
    "* Part H\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.formula.api import ols\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You're a Data Scientist...Which is Just a Statistician on a Mac, Right?\n",
    "\n",
    "Your models from the last assignment really impressed some of the management in your football club.  In the spirit of Moneyball (it was a book before it was a movie, I recomend you read it), managers want to test some hypotheses relating a player's overall rating and some of their characteristics in order to make better decisions on what players to trade/sign.\n",
    "\n",
    "Management heard somewhere on the internet that statistics and data science are more or less the same thing (the truth of this is the subject of many debates) and would now like you to create some *statistical models* for inference instead of prediction.\n",
    "\n",
    "In this assignment, you're going to take off your \"data\" hat and put on your \"science\" hat.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "To test some of the management's hypotheses, the football club has spent some money to go out and collect new data in `footballer_sample.csv`.  The variables are more or less the same from the previous dataset.\n",
    "\n",
    "The data contain 52 columns, including some information about the player, their skills, and their overall measure as an effective footballer.\n",
    "\n",
    "Most features relate to the player's abilities in football related skills, such as passing, shooting, dribbling, etc.  Some features are rated on a 1-5 scale (5 being the best), others are rated on 0-100 (100 being the best), and others still are categorical (e.g. work rate is coded as low, medium, or high).\n",
    "\n",
    "The target variable (or $y$ variable, if you will) is `overall`.  This is an overall measure of the footballer's skill and is rated from 0 to 100.  The most amazingly skilled footballer would be rated 100, where as I would struggle to score more than a 20. The model(s) you build should use the other features to predict `overall`.\n",
    "\n",
    "\n",
    "\n",
    "### Part A\n",
    "\n",
    "Read in the data and take a look at the dataframe.  There should be 52 columns. The outcome of interest is called `overall` which gives an overall measure of player performance. Not all of the other columns are particularly useful for modelling though (for instance, `ID` is just a unique identifier for the player.  This is essentially an arbitrary number and has no bearing on the player's rating).\n",
    "\n",
    "Remember that the Senior Data Scientist from the last assignment thinks the following columns should be removed:\n",
    "\n",
    "* ID\n",
    "* club\n",
    "* club_logo\n",
    "* birth_date\n",
    "* flag\n",
    "* nationality\n",
    "* photo\n",
    "* potential\n",
    "\n",
    "\n",
    "That still sounds like a pretty good idea.  Remove those columns.  Keep the categorical variables as they are encoded.  Statsmodels will automatically dummy encode them for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>overall</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>work_rate_att</th>\n",
       "      <th>work_rate_def</th>\n",
       "      <th>preferred_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>175.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Right</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>30</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>183.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Right</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>183.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Right</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>55</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>178.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>69</td>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Right</td>\n",
       "      <td>49</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>173.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Right</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>64</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>34</td>\n",
       "      <td>69</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height_cm  weight_kg  overall  pac  sho  pas  dri  def  phy  \\\n",
       "0   20      175.0       70.0       58   65   30   38   56   60   53   \n",
       "1   29      183.0       80.0       65   83   62   58   64   55   80   \n",
       "2   35      183.0       78.0       67   46   66   63   66   50   71   \n",
       "3   24      178.0       72.0       69   77   69   48   70   21   39   \n",
       "4   23      173.0       73.0       70   79   64   64   72   21   55   \n",
       "\n",
       "   international_reputation  skill_moves  weak_foot work_rate_att  \\\n",
       "0                         1            3          3        Medium   \n",
       "1                         1            2          3          High   \n",
       "2                         1            3          3          High   \n",
       "3                         1            3          3        Medium   \n",
       "4                         1            3          3        Medium   \n",
       "\n",
       "  work_rate_def preferred_foot  crossing  finishing  heading_accuracy  \\\n",
       "0          High          Right        55         27                53   \n",
       "1          High          Right        63         59                64   \n",
       "2           Low          Right        51         67                69   \n",
       "3        Medium          Right        49         70                67   \n",
       "4        Medium          Right        66         66                58   \n",
       "\n",
       "   short_passing  volleys  dribbling  curve  free_kick_accuracy  long_passing  \\\n",
       "0             33       26         63     33                  32            27   \n",
       "1             62       55         62     46                  59            43   \n",
       "2             69       61         65     63                  65            64   \n",
       "3             62       66         67     37                  43            39   \n",
       "4             68       64         70     46                  48            59   \n",
       "\n",
       "   ball_control  acceleration  sprint_speed  agility  reactions  balance  \\\n",
       "0            41            68            62       54         55       75   \n",
       "1            64            81            85       73         68       65   \n",
       "2            66            34            55       78         66       51   \n",
       "3            68            71            81       91         70       78   \n",
       "4            71            76            82       79         68       78   \n",
       "\n",
       "   shot_power  jumping  stamina  strength  long_shots  aggression  \\\n",
       "0          27       55       62        47          30          54   \n",
       "1          70       75       90        77          59          78   \n",
       "2          65       72       54        80          63          67   \n",
       "3          68       28       34        34          70          59   \n",
       "4          65       34       69        57          59          36   \n",
       "\n",
       "   interceptions  positioning  vision  penalties  composure  marking  \\\n",
       "0             60           54      40         45         43       53   \n",
       "1             53           60      61         68         65       52   \n",
       "2             59           70      64         67         65       45   \n",
       "3             25           73      34         59         54       11   \n",
       "4             19           67      66         63         63       13   \n",
       "\n",
       "   standing_tackle  \n",
       "0               70  \n",
       "1               56  \n",
       "2               43  \n",
       "3               17  \n",
       "4               18  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sampled_footballers.csv')\n",
    "model_data = df.drop(['ID','club','club_logo','flag', 'nationality','photo','potential', 'birth_date'], axis = 'columns')\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "In statistics, it is useful to *standardize* our data to have mean 0 and standard deviation 1.  This has the effect of putting all the variables on the same scale.  It also has the added benefit of easing the interpretation of the coefficients to the following:\n",
    "\n",
    ">Every 1 standard deviation change in the predictor $x$ results in a change of $\\beta$ in the outcome.\n",
    "\n",
    "Here, $\\beta$ is the coefficient from the linear model we fit to the data. Standardize all the numeric variables.  A good way to check that you've done this correctly is to compute the means (which should be close to 0) and the standard deviations (which should be close to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>overall</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.006484e-16</td>\n",
       "      <td>1.828537e-15</td>\n",
       "      <td>-1.386669e-16</td>\n",
       "      <td>-8.949508e-16</td>\n",
       "      <td>-2.138290e-16</td>\n",
       "      <td>1.287859e-17</td>\n",
       "      <td>1.921800e-16</td>\n",
       "      <td>1.021405e-16</td>\n",
       "      <td>-1.540990e-16</td>\n",
       "      <td>-1.546263e-16</td>\n",
       "      <td>3.235190e-16</td>\n",
       "      <td>-1.381117e-16</td>\n",
       "      <td>-1.012523e-16</td>\n",
       "      <td>-6.949996e-17</td>\n",
       "      <td>1.545430e-16</td>\n",
       "      <td>1.043610e-16</td>\n",
       "      <td>-2.059464e-17</td>\n",
       "      <td>1.056932e-16</td>\n",
       "      <td>3.197442e-17</td>\n",
       "      <td>3.330669e-17</td>\n",
       "      <td>-2.327027e-16</td>\n",
       "      <td>6.739054e-17</td>\n",
       "      <td>1.252332e-16</td>\n",
       "      <td>-7.482903e-17</td>\n",
       "      <td>-6.528111e-17</td>\n",
       "      <td>1.474376e-16</td>\n",
       "      <td>4.152234e-16</td>\n",
       "      <td>-1.620926e-16</td>\n",
       "      <td>1.283418e-16</td>\n",
       "      <td>1.660894e-16</td>\n",
       "      <td>1.891820e-16</td>\n",
       "      <td>5.873080e-17</td>\n",
       "      <td>-1.598721e-17</td>\n",
       "      <td>-2.045031e-16</td>\n",
       "      <td>1.274536e-16</td>\n",
       "      <td>1.383338e-16</td>\n",
       "      <td>2.587375e-16</td>\n",
       "      <td>1.381117e-16</td>\n",
       "      <td>1.982858e-16</td>\n",
       "      <td>1.700862e-16</td>\n",
       "      <td>7.904788e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "      <td>1.001002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.731859e+00</td>\n",
       "      <td>-2.635321e+00</td>\n",
       "      <td>-2.531461e+00</td>\n",
       "      <td>-2.829396e+00</td>\n",
       "      <td>-3.364140e+00</td>\n",
       "      <td>-2.248185e+00</td>\n",
       "      <td>-3.104085e+00</td>\n",
       "      <td>-3.157626e+00</td>\n",
       "      <td>-2.002142e+00</td>\n",
       "      <td>-3.309659e+00</td>\n",
       "      <td>-3.234206e-01</td>\n",
       "      <td>-1.760172e+00</td>\n",
       "      <td>-3.194121e+00</td>\n",
       "      <td>-2.307241e+00</td>\n",
       "      <td>-2.001035e+00</td>\n",
       "      <td>-2.690056e+00</td>\n",
       "      <td>-3.012803e+00</td>\n",
       "      <td>-2.148550e+00</td>\n",
       "      <td>-2.532915e+00</td>\n",
       "      <td>-2.074816e+00</td>\n",
       "      <td>-2.013266e+00</td>\n",
       "      <td>-2.643182e+00</td>\n",
       "      <td>-2.953177e+00</td>\n",
       "      <td>-3.280353e+00</td>\n",
       "      <td>-3.246441e+00</td>\n",
       "      <td>-3.257684e+00</td>\n",
       "      <td>-3.237410e+00</td>\n",
       "      <td>-3.082273e+00</td>\n",
       "      <td>-2.424026e+00</td>\n",
       "      <td>-3.084429e+00</td>\n",
       "      <td>-2.948054e+00</td>\n",
       "      <td>-3.238288e+00</td>\n",
       "      <td>-2.162624e+00</td>\n",
       "      <td>-2.391846e+00</td>\n",
       "      <td>-2.079895e+00</td>\n",
       "      <td>-2.285588e+00</td>\n",
       "      <td>-2.871219e+00</td>\n",
       "      <td>-2.581538e+00</td>\n",
       "      <td>-3.134522e+00</td>\n",
       "      <td>-1.884645e+00</td>\n",
       "      <td>-1.945798e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.717356e-01</td>\n",
       "      <td>-6.428134e-01</td>\n",
       "      <td>-7.476953e-01</td>\n",
       "      <td>-5.710733e-01</td>\n",
       "      <td>-6.408750e-01</td>\n",
       "      <td>-7.172926e-01</td>\n",
       "      <td>-6.591832e-01</td>\n",
       "      <td>-5.598259e-01</td>\n",
       "      <td>-8.330765e-01</td>\n",
       "      <td>-6.362672e-01</td>\n",
       "      <td>-3.234206e-01</td>\n",
       "      <td>-3.871830e-01</td>\n",
       "      <td>1.158490e-01</td>\n",
       "      <td>-7.106487e-01</td>\n",
       "      <td>-8.647291e-01</td>\n",
       "      <td>-4.907314e-01</td>\n",
       "      <td>-4.179078e-01</td>\n",
       "      <td>-7.216626e-01</td>\n",
       "      <td>-4.348284e-01</td>\n",
       "      <td>-6.726927e-01</td>\n",
       "      <td>-6.794921e-01</td>\n",
       "      <td>-6.340942e-01</td>\n",
       "      <td>-3.682604e-01</td>\n",
       "      <td>-5.990117e-01</td>\n",
       "      <td>-5.962297e-01</td>\n",
       "      <td>-5.726661e-01</td>\n",
       "      <td>-6.726390e-01</td>\n",
       "      <td>-6.023972e-01</td>\n",
       "      <td>-6.531628e-01</td>\n",
       "      <td>-5.971200e-01</td>\n",
       "      <td>-4.829249e-01</td>\n",
       "      <td>-5.775978e-01</td>\n",
       "      <td>-8.116983e-01</td>\n",
       "      <td>-6.732337e-01</td>\n",
       "      <td>-9.580395e-01</td>\n",
       "      <td>-6.027415e-01</td>\n",
       "      <td>-7.784939e-01</td>\n",
       "      <td>-6.634149e-01</td>\n",
       "      <td>-5.258986e-01</td>\n",
       "      <td>-1.060456e+00</td>\n",
       "      <td>-9.343731e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.161167e-02</td>\n",
       "      <td>-2.973434e-02</td>\n",
       "      <td>-4.459415e-03</td>\n",
       "      <td>-6.492677e-03</td>\n",
       "      <td>3.994122e-02</td>\n",
       "      <td>1.873255e-01</td>\n",
       "      <td>1.871290e-01</td>\n",
       "      <td>1.824027e-01</td>\n",
       "      <td>1.021764e-01</td>\n",
       "      <td>5.683432e-02</td>\n",
       "      <td>-3.234206e-01</td>\n",
       "      <td>-3.871830e-01</td>\n",
       "      <td>1.158490e-01</td>\n",
       "      <td>2.252847e-01</td>\n",
       "      <td>6.497606e-02</td>\n",
       "      <td>1.859839e-01</td>\n",
       "      <td>3.605606e-01</td>\n",
       "      <td>2.031888e-02</td>\n",
       "      <td>2.995018e-01</td>\n",
       "      <td>-5.662946e-03</td>\n",
       "      <td>-4.924705e-02</td>\n",
       "      <td>2.084267e-01</td>\n",
       "      <td>2.929973e-01</td>\n",
       "      <td>2.053908e-01</td>\n",
       "      <td>1.512659e-01</td>\n",
       "      <td>1.158000e-01</td>\n",
       "      <td>-3.568377e-03</td>\n",
       "      <td>1.415655e-01</td>\n",
       "      <td>2.608310e-01</td>\n",
       "      <td>1.076176e-01</td>\n",
       "      <td>1.784513e-01</td>\n",
       "      <td>1.065796e-01</td>\n",
       "      <td>1.495370e-01</td>\n",
       "      <td>1.499669e-01</td>\n",
       "      <td>2.377839e-01</td>\n",
       "      <td>2.579508e-01</td>\n",
       "      <td>1.235430e-01</td>\n",
       "      <td>3.989696e-02</td>\n",
       "      <td>1.448904e-01</td>\n",
       "      <td>1.758270e-01</td>\n",
       "      <td>2.839347e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.485122e-01</td>\n",
       "      <td>7.366145e-01</td>\n",
       "      <td>7.387764e-01</td>\n",
       "      <td>6.992331e-01</td>\n",
       "      <td>6.299820e-01</td>\n",
       "      <td>7.440136e-01</td>\n",
       "      <td>6.573025e-01</td>\n",
       "      <td>6.462955e-01</td>\n",
       "      <td>8.036160e-01</td>\n",
       "      <td>7.499358e-01</td>\n",
       "      <td>-3.234206e-01</td>\n",
       "      <td>9.858063e-01</td>\n",
       "      <td>1.158490e-01</td>\n",
       "      <td>7.758337e-01</td>\n",
       "      <td>8.397303e-01</td>\n",
       "      <td>6.935204e-01</td>\n",
       "      <td>6.849225e-01</td>\n",
       "      <td>7.623004e-01</td>\n",
       "      <td>6.797800e-01</td>\n",
       "      <td>7.566567e-01</td>\n",
       "      <td>7.568803e-01</td>\n",
       "      <td>7.269011e-01</td>\n",
       "      <td>6.536833e-01</td>\n",
       "      <td>6.913839e-01</td>\n",
       "      <td>6.948991e-01</td>\n",
       "      <td>7.354195e-01</td>\n",
       "      <td>6.655023e-01</td>\n",
       "      <td>7.438210e-01</td>\n",
       "      <td>7.749525e-01</td>\n",
       "      <td>6.465346e-01</td>\n",
       "      <td>7.195773e-01</td>\n",
       "      <td>7.147374e-01</td>\n",
       "      <td>7.990204e-01</td>\n",
       "      <td>7.854201e-01</td>\n",
       "      <td>8.295316e-01</td>\n",
       "      <td>6.947200e-01</td>\n",
       "      <td>8.090910e-01</td>\n",
       "      <td>7.432088e-01</td>\n",
       "      <td>6.666152e-01</td>\n",
       "      <td>8.283099e-01</td>\n",
       "      <td>8.126342e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.568760e+00</td>\n",
       "      <td>2.729122e+00</td>\n",
       "      <td>2.819837e+00</td>\n",
       "      <td>3.239846e+00</td>\n",
       "      <td>2.445492e+00</td>\n",
       "      <td>2.692422e+00</td>\n",
       "      <td>2.632031e+00</td>\n",
       "      <td>2.501867e+00</td>\n",
       "      <td>2.089589e+00</td>\n",
       "      <td>2.334168e+00</td>\n",
       "      <td>7.027048e+00</td>\n",
       "      <td>2.358795e+00</td>\n",
       "      <td>3.425819e+00</td>\n",
       "      <td>1.821877e+00</td>\n",
       "      <td>2.389239e+00</td>\n",
       "      <td>2.272523e+00</td>\n",
       "      <td>1.787753e+00</td>\n",
       "      <td>2.474565e+00</td>\n",
       "      <td>1.820615e+00</td>\n",
       "      <td>2.172393e+00</td>\n",
       "      <td>2.559674e+00</td>\n",
       "      <td>2.217515e+00</td>\n",
       "      <td>1.916084e+00</td>\n",
       "      <td>1.881229e+00</td>\n",
       "      <td>2.121936e+00</td>\n",
       "      <td>2.043505e+00</td>\n",
       "      <td>3.007250e+00</td>\n",
       "      <td>2.090039e+00</td>\n",
       "      <td>1.917445e+00</td>\n",
       "      <td>2.387651e+00</td>\n",
       "      <td>1.801829e+00</td>\n",
       "      <td>2.083092e+00</td>\n",
       "      <td>2.097987e+00</td>\n",
       "      <td>2.229632e+00</td>\n",
       "      <td>1.914402e+00</td>\n",
       "      <td>2.184874e+00</td>\n",
       "      <td>2.180187e+00</td>\n",
       "      <td>2.213770e+00</td>\n",
       "      <td>2.455386e+00</td>\n",
       "      <td>1.869993e+00</td>\n",
       "      <td>1.778086e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     height_cm     weight_kg       overall           pac  \\\n",
       "count  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean   3.006484e-16  1.828537e-15 -1.386669e-16 -8.949508e-16 -2.138290e-16   \n",
       "std    1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min   -1.731859e+00 -2.635321e+00 -2.531461e+00 -2.829396e+00 -3.364140e+00   \n",
       "25%   -8.717356e-01 -6.428134e-01 -7.476953e-01 -5.710733e-01 -6.408750e-01   \n",
       "50%   -1.161167e-02 -2.973434e-02 -4.459415e-03 -6.492677e-03  3.994122e-02   \n",
       "75%    8.485122e-01  7.366145e-01  7.387764e-01  6.992331e-01  6.299820e-01   \n",
       "max    2.568760e+00  2.729122e+00  2.819837e+00  3.239846e+00  2.445492e+00   \n",
       "\n",
       "                sho           pas           dri           def           phy  \\\n",
       "count  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean   1.287859e-17  1.921800e-16  1.021405e-16 -1.540990e-16 -1.546263e-16   \n",
       "std    1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min   -2.248185e+00 -3.104085e+00 -3.157626e+00 -2.002142e+00 -3.309659e+00   \n",
       "25%   -7.172926e-01 -6.591832e-01 -5.598259e-01 -8.330765e-01 -6.362672e-01   \n",
       "50%    1.873255e-01  1.871290e-01  1.824027e-01  1.021764e-01  5.683432e-02   \n",
       "75%    7.440136e-01  6.573025e-01  6.462955e-01  8.036160e-01  7.499358e-01   \n",
       "max    2.692422e+00  2.632031e+00  2.501867e+00  2.089589e+00  2.334168e+00   \n",
       "\n",
       "       international_reputation   skill_moves     weak_foot      crossing  \\\n",
       "count              5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean               3.235190e-16 -1.381117e-16 -1.012523e-16 -6.949996e-17   \n",
       "std                1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min               -3.234206e-01 -1.760172e+00 -3.194121e+00 -2.307241e+00   \n",
       "25%               -3.234206e-01 -3.871830e-01  1.158490e-01 -7.106487e-01   \n",
       "50%               -3.234206e-01 -3.871830e-01  1.158490e-01  2.252847e-01   \n",
       "75%               -3.234206e-01  9.858063e-01  1.158490e-01  7.758337e-01   \n",
       "max                7.027048e+00  2.358795e+00  3.425819e+00  1.821877e+00   \n",
       "\n",
       "          finishing  heading_accuracy  short_passing       volleys  \\\n",
       "count  5.000000e+02      5.000000e+02   5.000000e+02  5.000000e+02   \n",
       "mean   1.545430e-16      1.043610e-16  -2.059464e-17  1.056932e-16   \n",
       "std    1.001002e+00      1.001002e+00   1.001002e+00  1.001002e+00   \n",
       "min   -2.001035e+00     -2.690056e+00  -3.012803e+00 -2.148550e+00   \n",
       "25%   -8.647291e-01     -4.907314e-01  -4.179078e-01 -7.216626e-01   \n",
       "50%    6.497606e-02      1.859839e-01   3.605606e-01  2.031888e-02   \n",
       "75%    8.397303e-01      6.935204e-01   6.849225e-01  7.623004e-01   \n",
       "max    2.389239e+00      2.272523e+00   1.787753e+00  2.474565e+00   \n",
       "\n",
       "          dribbling         curve  free_kick_accuracy  long_passing  \\\n",
       "count  5.000000e+02  5.000000e+02        5.000000e+02  5.000000e+02   \n",
       "mean   3.197442e-17  3.330669e-17       -2.327027e-16  6.739054e-17   \n",
       "std    1.001002e+00  1.001002e+00        1.001002e+00  1.001002e+00   \n",
       "min   -2.532915e+00 -2.074816e+00       -2.013266e+00 -2.643182e+00   \n",
       "25%   -4.348284e-01 -6.726927e-01       -6.794921e-01 -6.340942e-01   \n",
       "50%    2.995018e-01 -5.662946e-03       -4.924705e-02  2.084267e-01   \n",
       "75%    6.797800e-01  7.566567e-01        7.568803e-01  7.269011e-01   \n",
       "max    1.820615e+00  2.172393e+00        2.559674e+00  2.217515e+00   \n",
       "\n",
       "       ball_control  acceleration  sprint_speed       agility     reactions  \\\n",
       "count  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean   1.252332e-16 -7.482903e-17 -6.528111e-17  1.474376e-16  4.152234e-16   \n",
       "std    1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min   -2.953177e+00 -3.280353e+00 -3.246441e+00 -3.257684e+00 -3.237410e+00   \n",
       "25%   -3.682604e-01 -5.990117e-01 -5.962297e-01 -5.726661e-01 -6.726390e-01   \n",
       "50%    2.929973e-01  2.053908e-01  1.512659e-01  1.158000e-01 -3.568377e-03   \n",
       "75%    6.536833e-01  6.913839e-01  6.948991e-01  7.354195e-01  6.655023e-01   \n",
       "max    1.916084e+00  1.881229e+00  2.121936e+00  2.043505e+00  3.007250e+00   \n",
       "\n",
       "            balance    shot_power       jumping       stamina      strength  \\\n",
       "count  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean  -1.620926e-16  1.283418e-16  1.660894e-16  1.891820e-16  5.873080e-17   \n",
       "std    1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min   -3.082273e+00 -2.424026e+00 -3.084429e+00 -2.948054e+00 -3.238288e+00   \n",
       "25%   -6.023972e-01 -6.531628e-01 -5.971200e-01 -4.829249e-01 -5.775978e-01   \n",
       "50%    1.415655e-01  2.608310e-01  1.076176e-01  1.784513e-01  1.065796e-01   \n",
       "75%    7.438210e-01  7.749525e-01  6.465346e-01  7.195773e-01  7.147374e-01   \n",
       "max    2.090039e+00  1.917445e+00  2.387651e+00  1.801829e+00  2.083092e+00   \n",
       "\n",
       "         long_shots    aggression  interceptions   positioning        vision  \\\n",
       "count  5.000000e+02  5.000000e+02   5.000000e+02  5.000000e+02  5.000000e+02   \n",
       "mean  -1.598721e-17 -2.045031e-16   1.274536e-16  1.383338e-16  2.587375e-16   \n",
       "std    1.001002e+00  1.001002e+00   1.001002e+00  1.001002e+00  1.001002e+00   \n",
       "min   -2.162624e+00 -2.391846e+00  -2.079895e+00 -2.285588e+00 -2.871219e+00   \n",
       "25%   -8.116983e-01 -6.732337e-01  -9.580395e-01 -6.027415e-01 -7.784939e-01   \n",
       "50%    1.495370e-01  1.499669e-01   2.377839e-01  2.579508e-01  1.235430e-01   \n",
       "75%    7.990204e-01  7.854201e-01   8.295316e-01  6.947200e-01  8.090910e-01   \n",
       "max    2.097987e+00  2.229632e+00   1.914402e+00  2.184874e+00  2.180187e+00   \n",
       "\n",
       "          penalties     composure       marking  standing_tackle  \n",
       "count  5.000000e+02  5.000000e+02  5.000000e+02     5.000000e+02  \n",
       "mean   1.381117e-16  1.982858e-16  1.700862e-16     7.904788e-17  \n",
       "std    1.001002e+00  1.001002e+00  1.001002e+00     1.001002e+00  \n",
       "min   -2.581538e+00 -3.134522e+00 -1.884645e+00    -1.945798e+00  \n",
       "25%   -6.634149e-01 -5.258986e-01 -1.060456e+00    -9.343731e-01  \n",
       "50%    3.989696e-02  1.448904e-01  1.758270e-01     2.839347e-01  \n",
       "75%    7.432088e-01  6.666152e-01  8.283099e-01     8.126342e-01  \n",
       "max    2.213770e+00  2.455386e+00  1.869993e+00     1.778086e+00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (0, len(model_data.columns)):\n",
    "    col = model_data.columns[i]\n",
    "    if model_data[col].dtypes != 'object':\n",
    "        model_data[col] = preprocessing.scale(model_data[col])\n",
    "        \n",
    "model_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "One of the things scouts like to disagree upon is how a player changes as they age.  Some insist that players hit their prime in their late 20s and as they reach middle age, they become worse because they can't keep up with younger players.\n",
    "\n",
    "Other scouts are certain that the experience a player gains over their tenure makes them more valuable; they can anticipate what will happen on the field much better than a new player.\n",
    "\n",
    "You decide that a quadratic term for age in a statistical model might be worth investigating. Write down a statistical model for these competing hypotheses.  What is the null hypothesis? What is the alternative hypothesis?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: Age has no significant effect on the response variable.\n",
    "Alternative hypothesis: Age has a significant effect on the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Fit your model from Part C.  What can you conclude from the model about the quadratic effect of age within the quadratic model?  Answer in terms of the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: We reject the null hypothesis as there is evidence of a significant negative associate between quadratic age term and overall performance. I will not though, when you compare models using age, age**2 and age**2 + age, you see consistently that age has a positive association with overall and age**2 has a negative association. I suspect that, since the only different isn the growth rate, the effect of age helps your overall score until a certain point then it begins to hurt it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:16:21</td>     <th>  Log-Likelihood:    </th> <td> -704.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1414.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   1422.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    0.1156</td> <td>    0.059</td> <td>    1.970</td> <td> 0.049</td> <td>    0.000</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(age ** 2)</th> <td>   -0.1156</td> <td>    0.038</td> <td>   -3.015</td> <td> 0.003</td> <td>   -0.191</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.020</td> <th>  Durbin-Watson:     </th> <td>   2.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.601</td> <th>  Jarque-Bera (JB):  </th> <td>   0.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.107</td> <th>  Prob(JB):          </th> <td>   0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.006</td> <th>  Cond. No.          </th> <td>    2.48</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.018\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     9.089\n",
       "Date:                Mon, 02 Mar 2020   Prob (F-statistic):            0.00270\n",
       "Time:                        11:16:21   Log-Likelihood:                -704.95\n",
       "No. Observations:                 500   AIC:                             1414.\n",
       "Df Residuals:                     498   BIC:                             1422.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       0.1156      0.059      1.970      0.049       0.000       0.231\n",
       "I(age ** 2)    -0.1156      0.038     -3.015      0.003      -0.191      -0.040\n",
       "==============================================================================\n",
       "Omnibus:                        1.020   Durbin-Watson:                   2.050\n",
       "Prob(Omnibus):                  0.601   Jarque-Bera (JB):                0.964\n",
       "Skew:                           0.107   Prob(JB):                        0.618\n",
       "Kurtosis:                       3.006   Cond. No.                         2.48\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = ols('overall ~ I(age**2)', data=model_data).fit()\n",
    "\n",
    "M1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "Management would also like to know how marking (the player's ability to prevent the other team from getting the ball) and interceptions (taking the ball when the opposing team is passing the ball between players) impact a player's overall ranking, controlling for age.\n",
    "\n",
    "Marking and interceptions sound awfully similar, don't they? Fit two models: one model only controls for age (including the quadratic term) and marking, the other controls for age (including the quadratic term), marking, AND interceptions.\n",
    "\n",
    "Answer the following:\n",
    "\n",
    "* At the level of model-inference (based on on AIC) which one is the better model for the data? \n",
    "\n",
    "* At the level of parameter based inference, does marking have a positive, negative, or no influence on the overall ability? How does this conclusion differ bewteen the first and second model?  \n",
    "\n",
    "* Why is this difference troubling? How does the interpretation of a one standard deviation change in marking change between models?\n",
    "\n",
    "* Sentences, what might explain this difference? You might want to look at `model_data.corr()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: From the results below we can answer the following questions.\n",
    "* At the level of model-inference (based on on AIC) which one is the better model for the data?\n",
    "\n",
    "* At the level of parameter based inference, does marking have a positive, negative, or no influence on the overall ability? How does this conclusion differ bewteen the first and second model?\n",
    "In the first model, Marking appears to have a significant and positive influence on overall ability. But in the second model, when interceptions were included, marking still has a significant effect on the overall ability (although alot less significant) but it's appears to be negative.\n",
    "\n",
    "* Why is this difference troubling? How does the interpretation of a one standard deviation change in marking change between models?\n",
    "This difference is troubling because, when looking at the second model, if we knew no better we would conclude that marking is an undesired trait. When looking at the first model we might conclude that marking has a causal relationship with overall.\n",
    "\n",
    "* Sentences, what might explain this difference? You might want to look at model_data.corr().\n",
    "This is caused by colliniearity. This is clear to see in the corelation matrix plotted below, marking and interceptions have a corelation of 0.94.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age + marking vs. age + marking + interceptions:  11.186029740812046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   84.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>3.70e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:05:23</td>     <th>  Log-Likelihood:    </th> <td> -606.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1221.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   496</td>      <th>  BIC:               </th> <td>   1237.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    0.2449</td> <td>    0.049</td> <td>    4.990</td> <td> 0.000</td> <td>    0.148</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>         <td>    0.5501</td> <td>    0.038</td> <td>   14.299</td> <td> 0.000</td> <td>    0.475</td> <td>    0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(age ** 2)</th> <td>   -0.2449</td> <td>    0.033</td> <td>   -7.473</td> <td> 0.000</td> <td>   -0.309</td> <td>   -0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marking</th>     <td>    0.1287</td> <td>    0.037</td> <td>    3.473</td> <td> 0.001</td> <td>    0.056</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>19.398</td> <th>  Durbin-Watson:     </th> <td>   2.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  20.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.461</td> <th>  Prob(JB):          </th> <td>3.14e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.383</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.338\n",
       "Model:                            OLS   Adj. R-squared:                  0.334\n",
       "Method:                 Least Squares   F-statistic:                     84.46\n",
       "Date:                Mon, 02 Mar 2020   Prob (F-statistic):           3.70e-44\n",
       "Time:                        11:05:23   Log-Likelihood:                -606.30\n",
       "No. Observations:                 500   AIC:                             1221.\n",
       "Df Residuals:                     496   BIC:                             1237.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       0.2449      0.049      4.990      0.000       0.148       0.341\n",
       "age             0.5501      0.038     14.299      0.000       0.475       0.626\n",
       "I(age ** 2)    -0.2449      0.033     -7.473      0.000      -0.309      -0.180\n",
       "marking         0.1287      0.037      3.473      0.001       0.056       0.202\n",
       "==============================================================================\n",
       "Omnibus:                       19.398   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               20.736\n",
       "Skew:                           0.461   Prob(JB):                     3.14e-05\n",
       "Kurtosis:                       3.383   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   68.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>5.70e-46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:05:23</td>     <th>  Log-Likelihood:    </th> <td> -599.70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1209.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   495</td>      <th>  BIC:               </th> <td>   1230.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    0.2381</td> <td>    0.049</td> <td>    4.907</td> <td> 0.000</td> <td>    0.143</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>           <td>    0.5222</td> <td>    0.039</td> <td>   13.469</td> <td> 0.000</td> <td>    0.446</td> <td>    0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(age ** 2)</th>   <td>   -0.2381</td> <td>    0.032</td> <td>   -7.342</td> <td> 0.000</td> <td>   -0.302</td> <td>   -0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marking</th>       <td>   -0.2276</td> <td>    0.105</td> <td>   -2.176</td> <td> 0.030</td> <td>   -0.433</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interceptions</th> <td>    0.3849</td> <td>    0.106</td> <td>    3.637</td> <td> 0.000</td> <td>    0.177</td> <td>    0.593</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.550</td> <th>  Durbin-Watson:     </th> <td>   1.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  18.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.430</td> <th>  Prob(JB):          </th> <td>8.96e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.392</td> <th>  Cond. No.          </th> <td>    6.94</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.355\n",
       "Model:                            OLS   Adj. R-squared:                  0.350\n",
       "Method:                 Least Squares   F-statistic:                     68.22\n",
       "Date:                Mon, 02 Mar 2020   Prob (F-statistic):           5.70e-46\n",
       "Time:                        11:05:23   Log-Likelihood:                -599.70\n",
       "No. Observations:                 500   AIC:                             1209.\n",
       "Df Residuals:                     495   BIC:                             1230.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept         0.2381      0.049      4.907      0.000       0.143       0.333\n",
       "age               0.5222      0.039     13.469      0.000       0.446       0.598\n",
       "I(age ** 2)      -0.2381      0.032     -7.342      0.000      -0.302      -0.174\n",
       "marking          -0.2276      0.105     -2.176      0.030      -0.433      -0.022\n",
       "interceptions     0.3849      0.106      3.637      0.000       0.177       0.593\n",
       "==============================================================================\n",
       "Omnibus:                       17.550   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.641\n",
       "Skew:                           0.430   Prob(JB):                     8.96e-05\n",
       "Kurtosis:                       3.392   Cond. No.                         6.94\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marking</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165444</td>\n",
       "      <td>0.220115</td>\n",
       "      <td>0.495185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marking</th>\n",
       "      <td>0.165444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937530</td>\n",
       "      <td>0.215693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interceptions</th>\n",
       "      <td>0.220115</td>\n",
       "      <td>0.937530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.283084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.495185</td>\n",
       "      <td>0.215693</td>\n",
       "      <td>0.283084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    age   marking  interceptions   overall\n",
       "age            1.000000  0.165444       0.220115  0.495185\n",
       "marking        0.165444  1.000000       0.937530  0.215693\n",
       "interceptions  0.220115  0.937530       1.000000  0.283084\n",
       "overall        0.495185  0.215693       0.283084  1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = model_data\n",
    "M1 = ols('overall ~ age + I(age**2) + marking', data=model_data).fit()\n",
    "M2 = ols('overall ~ age + I(age**2) + marking + interceptions', data=model_data).fit()\n",
    "\n",
    "\n",
    "# model-inference (based on on AIC) \n",
    "print('age + marking vs. age + marking + interceptions: ',M1.aic - M2.aic)\n",
    "\n",
    "# parameter based inference  \n",
    "display(M1.summary())\n",
    "display(M2.summary())\n",
    "\n",
    "# Correlation table\n",
    "\n",
    "model_data.loc[:,['age','marking','interceptions','overall']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "Fit the linear model `overall~ preferred_foot`.  Incredibly, the model says that **RIGHT FOOTED PLAYERS TEND TO BE WORSE AS COMPARED TO LEFT FOOTED PLAYERS**! Scounts don't believe you, this goes against everything they've believed about being left footed.  \n",
    "\n",
    "Perform a randomization test on this data.  Perform 1000 randomizations of `preferred_foot`, fit the same model, and record the effects.  Plot a histogram of the effects from the randomized data and use `plt.axvline` to plot a vertical red line to indicate where the observed effect from our data lies.\n",
    "\n",
    "Print out the p value (that is, the proportion of the resampled effects are larger than our observed effect in absolute value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:05:55</td>     <th>  Log-Likelihood:    </th> <td> -704.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   1414.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   498</td>      <th>  BIC:               </th> <td>   1422.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    0.2447</td> <td>    0.091</td> <td>    2.678</td> <td> 0.008</td> <td>    0.065</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>preferred_foot[T.Right]</th> <td>   -0.3203</td> <td>    0.105</td> <td>   -3.063</td> <td> 0.002</td> <td>   -0.526</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.247</td> <th>  Durbin-Watson:     </th> <td>   2.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.536</td> <th>  Jarque-Bera (JB):  </th> <td>   1.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.038</td> <th>  Prob(JB):          </th> <td>   0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.213</td> <th>  Cond. No.          </th> <td>    3.90</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.018\n",
       "Model:                            OLS   Adj. R-squared:                  0.017\n",
       "Method:                 Least Squares   F-statistic:                     9.385\n",
       "Date:                Mon, 02 Mar 2020   Prob (F-statistic):            0.00231\n",
       "Time:                        11:05:55   Log-Likelihood:                -704.80\n",
       "No. Observations:                 500   AIC:                             1414.\n",
       "Df Residuals:                     498   BIC:                             1422.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   0.2447      0.091      2.678      0.008       0.065       0.424\n",
       "preferred_foot[T.Right]    -0.3203      0.105     -3.063      0.002      -0.526      -0.115\n",
       "==============================================================================\n",
       "Omnibus:                        1.247   Durbin-Watson:                   2.054\n",
       "Prob(Omnibus):                  0.536   Jarque-Bera (JB):                1.065\n",
       "Skew:                           0.038   Prob(JB):                        0.587\n",
       "Kurtosis:                       3.213   Cond. No.                         3.90\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our p value is:  0.001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def randomize_column (df,colname):\n",
    "    df_copy = df.copy()\n",
    "    var = df_copy[colname].values\n",
    "    np.random.shuffle(var)\n",
    "    df_copy[colname]=var\n",
    "    return df_copy\n",
    "\n",
    "display(ols('overall ~ preferred_foot', data=model_data).fit().summary())\n",
    "\n",
    "# Get the effect we see from the data\n",
    "observed_effect = ols('overall ~ preferred_foot', data=model_data).fit().params[1]\n",
    "\n",
    "# Initialize somewhere to put the resampled effects\n",
    "randomization_tests = np.zeros(1000)\n",
    "\n",
    "for i in range(1000):\n",
    "    # Randomize the overall\n",
    "    Model_D=randomize_column(model_data,'preferred_foot')\n",
    "    # Estimate the effect of weight now that we have shuffled overall\n",
    "    shuffled_model = ols('overall ~ preferred_foot',data =Model_D ).fit()\n",
    "    # Stick the result in this array\n",
    "    randomization_tests[i]=shuffled_model.params[1]\n",
    "\n",
    "# Plots\n",
    "plt.hist(randomization_tests,bins=50)\n",
    "plt.axvline(observed_effect, color = 'red')\n",
    "\n",
    "p_value = np.mean(np.abs(randomization_tests)>np.abs(observed_effect))\n",
    "print('Our p value is: ', p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part G\n",
    "\n",
    "Your findings from the randomization test are incredible; left footed players are on average 2.5 points better than their right footed counterparts!  The management is prepared to spend a lot of money to replace the team full of lefties in order to gain a slight advantage.\n",
    "\n",
    "However, you have a sneaking suspicion this isn't the whole story.  Before management replaces the entire team, you decide to take a look at the dataset from your predictive model, called `footballer_data.csv`.  Load that data, clean it up as you did in part A, and perform another regression of overall onto preferred_foot, this time controlling for age (including the quadratic term) and interceptions.  Answer the following in a markdown cell:\n",
    "\n",
    "* What is the p-value for the effect of being right footed?  \n",
    "* What does that mean in terms of the null hypothesis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: p-value is 0.243. This gives us reason not to reject the null hypothesis of there being a significant effect from foot_preffered to overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.324</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.324</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2157.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:06:02</td>     <th>  Log-Likelihood:    </th> <td> -56885.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 17994</td>      <th>  AIC:               </th> <td>1.138e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 17989</td>      <th>  BIC:               </th> <td>1.138e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    3.6941</td> <td>    1.149</td> <td>    3.216</td> <td> 0.001</td> <td>    1.442</td> <td>    5.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>preferred_foot[T.Right]</th> <td>   -0.1176</td> <td>    0.101</td> <td>   -1.168</td> <td> 0.243</td> <td>   -0.315</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                     <td>    4.0963</td> <td>    0.090</td> <td>   45.382</td> <td> 0.000</td> <td>    3.919</td> <td>    4.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(age ** 2)</th>             <td>   -0.0666</td> <td>    0.002</td> <td>  -38.724</td> <td> 0.000</td> <td>   -0.070</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interceptions</th>           <td>    0.0692</td> <td>    0.002</td> <td>   32.490</td> <td> 0.000</td> <td>    0.065</td> <td>    0.073</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>466.844</td> <th>  Durbin-Watson:     </th> <td>   0.590</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 531.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.364</td>  <th>  Prob(JB):          </th> <td>3.28e-116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.425</td>  <th>  Cond. No.          </th> <td>1.89e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.89e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.324\n",
       "Model:                            OLS   Adj. R-squared:                  0.324\n",
       "Method:                 Least Squares   F-statistic:                     2157.\n",
       "Date:                Mon, 02 Mar 2020   Prob (F-statistic):               0.00\n",
       "Time:                        11:06:02   Log-Likelihood:                -56885.\n",
       "No. Observations:               17994   AIC:                         1.138e+05\n",
       "Df Residuals:                   17989   BIC:                         1.138e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   3.6941      1.149      3.216      0.001       1.442       5.946\n",
       "preferred_foot[T.Right]    -0.1176      0.101     -1.168      0.243      -0.315       0.080\n",
       "age                         4.0963      0.090     45.382      0.000       3.919       4.273\n",
       "I(age ** 2)                -0.0666      0.002    -38.724      0.000      -0.070      -0.063\n",
       "interceptions               0.0692      0.002     32.490      0.000       0.065       0.073\n",
       "==============================================================================\n",
       "Omnibus:                      466.844   Durbin-Watson:                   0.590\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              531.822\n",
       "Skew:                           0.364   Prob(JB):                    3.28e-116\n",
       "Kurtosis:                       3.425   Cond. No.                     1.89e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.89e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_2 = pd.read_csv('footballer_data.csv')\n",
    "model_data_2 = df_2.drop(['ID','club','club_logo','flag', 'nationality','photo','potential', 'birth_date'], axis = 'columns')\n",
    "model_data.head()\n",
    "display(ols('overall ~ age + I(age**2) +preferred_foot+ interceptions', data=model_data_2).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part H\n",
    "\n",
    "The club owner, Owen Owner, saw the results of your randomization test and is convinced that he should replace the whole team with left-footed players. Using your results from Part G, write an email explaining to him why this isn't a worthwhile endeavour. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Owen Owner,\n",
    "\n",
    "Thank you for taking the time to look at my statistical analysis. Regarding the club's preference for left-footed players as a result of the randomization test you saw...\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "Junior Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
