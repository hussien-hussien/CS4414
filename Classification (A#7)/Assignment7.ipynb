{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Classification with Logistic Regression\n",
    "\n",
    "# Total: 20 pts\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Complete the assignment\n",
    "\n",
    "* Once the notebook is complete, restart your kernel and rerun your cells\n",
    "\n",
    "* Submit this notebook to owl by the deadline\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "You can read more about the data and the variables [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need these\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, make_scorer, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: 1 pt\n",
    "\n",
    "Read in the `diabetes.csv` dataset. How many variables and how many observations? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: 1 pt\n",
    "\n",
    "Then split the data into train and test for the outcome and the predictor variables.  Hold out 50% of observations as the test set.  Pass `random_state=0` to `train_test_split` to ensure you get the same train and tests sets as the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis='columns')\n",
    "y = df.Outcome\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,\n",
    "                                                y, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: 1 pts\n",
    "\n",
    "Read the documentation for [sklearn's `LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).  In no more than 2 sentences per bullet point, answer the following in your own words.\n",
    "\n",
    "* Does `LogisticRegression` use a penalty by default?  If yes, what penalty?  If it does, does this mean that `LogisticRegression` actually uses ridge regression or the LASSO as the default?\n",
    "\n",
    "* What is the interpretation of the paramater `C`?  How does it relate to the regularization strength $\\lambda$?\n",
    "\n",
    "\n",
    "* If I were to ask you to use a regularization strengh of 2 (i.e. $\\lambda=2$), what value of `C` would you pass?\n",
    "\n",
    "Answer in the cell below using markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers go here!\n",
    "* Yes, there is an l2 penalty by default. This means it uses ridge regression by default.\n",
    "* Inverse of regularization strength; must be a positive float. Smaller values specify stronger regularization. C = INV(ùúÜ)\n",
    "* 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: 3 pts\n",
    "\n",
    "Create a instance of sklearn's `LogisticRegression` object for simple logistic regression (that is, the unpenalized version).  You will need to choose an alternative solver for `LogisticRegression` since the default solver does not support the no penalty option. Any solver will do, so just take a look at the docs to see what is available. I used `solver=\"newton-cg\"` which seems to work fine.\n",
    "\n",
    "Note: If you get a warning about convergence of `coef_`, try increasing the `max_iter` parameter.  I used `max_iter=10000` which seems to supress the warning.\n",
    "\n",
    "Using this object, run a logisitic regression analysis of `Outcome` (y-variable) against `Glucose` (x-variable) on your training data. Make a scatter-plot of x and y and add the class prediction (0 or 1, using `predict`) and the predicted probability of a positive outcome (using `predict_proba`). Note that `predict_proba` will return both p(Outcome=0) and p(Outcome=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12f2f6910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR=  LogisticRegression(solver='newton-cg', penalty = 'none',max_iter=10000)\n",
    "tempX = np.array(Xtrain['Glucose']).reshape(-1, 1)\n",
    "LR.fit(tempX, ytrain)\n",
    "\n",
    "## Scatter Plot\n",
    "ytest_pred = LR.predict(tempX)\n",
    "ytest_pred_prob = LR.predict_proba(tempX)\n",
    "plt.scatter(ytest_pred_prob[:,1], ytest_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: 1 pt\n",
    "Using the normal logistic regression from Question 4 to fit a model to predict outcome from all the variables in the data frame. Report the coefficients. Which variable increases the probability of having diabetes, and which variables decrease the probability of having diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09842832,  0.03212676, -0.00774468,  0.00496927, -0.00134285,\n",
       "         0.08025972,  1.09714211,  0.01828924]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR=  LogisticRegression(solver='newton-cg', penalty = 'none',max_iter=10000)\n",
    "lr = LR.fit(Xtrain, ytrain)\n",
    "lr.coef_\n",
    "\n",
    "## It appears that the variables that increase the probability of diabetes are:\n",
    "# Pregnancies,Glucose,SkinThickness,BMI,DiabetesPedigreeFunction,Age\n",
    "## The variables that seem to decrease the probabilities are:\n",
    "# Insulin,BloodPressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: 3 pts\n",
    "\n",
    "Use your model to construct a confusion matrix by fitting and predicting on the training data (I've inlcluded a little helper function to make looking at the confusion matrix a little easier). Then answer the following using the confusion matrix (don't use sklearn's functions):\n",
    "\n",
    "* What is your model's training accuracy?\n",
    "* What is your model's training precision?\n",
    "* What is your model's training recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12f4cc390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('equal')\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    return ax\n",
    "\n",
    "y_true = ytrain\n",
    "y_pred = lr.predict(Xtrain)\n",
    "classes = lr.classes_\n",
    "plot_confusion_matrix(y_true,y_pred, classes)\n",
    "\n",
    "# What is your model's training accuracy?\n",
    "# Accuracy \n",
    "    # = tp + tn / tp + tn + fp + fn \n",
    "    # = 216+28 /216 +78 + 31 + 69\n",
    "    # = 0.765625\n",
    "# What is your model's training precision?\n",
    "# Precision\n",
    "    # = tp / tp +fp\n",
    "    # = 78 / 78 + 31\n",
    "    # = 0.71\n",
    "# What is your model's training recall?\n",
    "# Recall\n",
    "    # = tp / tp +fn\n",
    "    # = 78 / 78 + 59\n",
    "    # = 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:  1 pts\n",
    "\n",
    "Estimate logistic regression's out of sample recall by using 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-61e9adc2b4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "cross_val_score(clf, Xtrain, ytrain).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: 1 pt\n",
    "\n",
    "Create new pipelines for l2 penalty in logistic regression and an l1 penalty.  Remember, penalized models perform best when you scale the inputs.  You should add `StandardScaler()` to your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('logistic', LogisticRegression(solver='saga'))\n",
    "])\n",
    "\n",
    "#interact_model = model_pipeline.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: 3 pts\n",
    "\n",
    "  Use sklearn's `GridSearchCV` to search over the regularization strength ranging from 0.1 to 1000 in 30 evenly spaced increments for your models. Vary the parameter evenly in log-space. Use recall as your metric for scoring.  \n",
    "Plot the score for both lasso and ridge as a function of the log-regularization parameter. \n",
    "\n",
    "`GridSearchCV` is a way to cross validate your models for a variety of parameters.  Read more about `GridSearchCV` [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of values of the regularization parameter\n",
    "Cs = np.linspace(0.1,1000,30)\n",
    "C = np.exp(Cs)\n",
    "# Create a list of options for the regularization penalty\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "parameters = dict(logistic__C=C,\n",
    "                  logistic__penalty=penalty)\n",
    "\n",
    "clf = GridSearchCV(model_pipeline, parameters, scoring='recall', verbose = 1)\n",
    "\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "scores = [x for x in clf.cv_results_['mean_test_score']]\n",
    "scores = np.array(scores).reshape(len(penalty), len(Cs))\n",
    "\n",
    "for ind, i in enumerate(penalty):\n",
    "    plt.plot(Cs, scores[ind], label='C: ' + str(i))\n",
    "plt.legend()\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10: 1 pt\n",
    "\n",
    "Print the cross validated recall for your regularized models.  If you called your model grid search `lasso_gscv` you can access the best model's score by performing `lasso_gscv.best_score_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validated recall\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11: 4 pts\n",
    "\n",
    "LASSO makes the assumption that the model is what we call *sparse* (that means, not every variable is actually related to the outcome).  We can see which variables are more important than others by examining what is known as the *coefficient paths*.\n",
    "\n",
    "Here are the steps to create the coefficient path:\n",
    "\n",
    "1) Initialize an array of regularization strengths (typically going from something very small, maybe 0.1, to something very large, maybe 1000.\n",
    "\n",
    "2) For each regularization strength, fit your model.  Keep track of the coefficients somehow, either by initializing an empty array to store the coefficients or by appending them to a list.\n",
    "\n",
    "3) Plot the coefficient values against the log of the regularization strength.\n",
    "\n",
    "For an example + example code - see Lab05 - last item. \n",
    "\n",
    "You've done this correctly if you can create a plot which looks like [this](https://cvxpy.readthedocs.io/en/latest/_images/lasso_regression_11_0.svg).\n",
    "\n",
    "* Construct the coefficient path for logistic regression with an l1 penalty.\n",
    "* Determine which coefficient is most strongly related to the outcome by examining which coefficent reaches 0 last.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a full path for Lasso\n",
    "Cs = np.linspace(0.1,1000,100)\n",
    "C = np.exp(Cs)\n",
    "coefs = []\n",
    "for i in range(len(C)):\n",
    "    LR=  LogisticRegression(solver='saga', penalty = 'l1',max_iter=10000, C=C[i])\n",
    "    lr = LR.fit(Xtrain, ytrain)\n",
    "    coefs.append(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'r', 'g', 'c', 'k','c']\n",
    "for i in range(len(lr.coef_)):\n",
    "    y = [item[i] for item in coefs]\n",
    "    l1 = plt.plot(Cs,y, c=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.classes_ == [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
