{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn.model_selection\n",
    "import statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.stats.proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Interval Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PTSD paper, there were 52 test cases, 42 of which were correct\n",
    "\n",
    "n = 52\n",
    "c = 42\n",
    "\n",
    "# Create array of zeros, size n\n",
    "rawdata = np.zeros(n)\n",
    "\n",
    "# Set first c elements to 1\n",
    "rawdata[range(c)] = 1\n",
    "\n",
    "# Create pandas data frame\n",
    "data = pd.DataFrame({\"Match\": rawdata})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 10000 bootstrap datasets, compute means in each\n",
    "\n",
    "def createBootstrapMeans(data):\n",
    "    numboot = 10000\n",
    "    n = len(data)\n",
    "    boot_means = np.zeros(numboot)\n",
    "    np.random.seed(0)\n",
    "    for i in range(numboot):\n",
    "        d = data.sample(n, replace=True)\n",
    "        boot_means[i] = d.mean()\n",
    "    return boot_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "bm = createBootstrapMeans(data)\n",
    "sns.distplot(bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence interval\n",
    "\n",
    "boot_ci = np.quantile(bm, [0.025, 0.975])\n",
    "print(boot_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using central limit theorem, compute confidence interval\n",
    "\n",
    "stderr = np.std(data.Match,ddof=1)/np.sqrt(len(data.Match))\n",
    "print(f\"Stderr: {stderr}\")\n",
    "\n",
    "# Area under a standard normal from -1.96 to 1.96 is about 95%\n",
    "critval = 1.96\n",
    "print(f\"Critical value: {critval}\")\n",
    "\n",
    "norm_ci = [data.Match.mean() - critval*stderr, \n",
    "           data.Match.mean() + critval*stderr]\n",
    "\n",
    "print(f\"Boot ci: {boot_ci}\")\n",
    "print(f\"Norm ci: {norm_ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using t-distribution\n",
    "# Degrees of freedom of t distribution for this method is n-1\n",
    "\n",
    "my_df = len(data.Match) - 1\n",
    "\n",
    "# The ppf function is the inverse of the CDF. Given a probability p,\n",
    "# it tells us the x for which CDF(x) = p\n",
    "\n",
    "critval = scipy.stats.t.ppf(0.975, df=my_df)\n",
    "print(f\"Critical value: {critval}\")\n",
    "\n",
    "t_ci = [data.Match.mean() - critval*stderr, \n",
    "        data.Match.mean() + critval*stderr]\n",
    "\n",
    "print(f\"Boot ci: {boot_ci}\")\n",
    "print(f\"Norm ci: {norm_ci}\")\n",
    "print(f\"   t ci: {t_ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy approximate confidence intervals\n",
    "model = sm.ols('Match ~ 1', data = data).fit()\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "print(f\"Boot ci: {boot_ci}\")\n",
    "print(f\"Norm ci: {norm_ci}\")\n",
    "print(f\"   t ci: {t_ci}\")\n",
    "print(f\"{c} {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction bootstrap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: 1000 births from North Carolina\n",
    "# https://www.openintro.org/stat/data/?data=nc\n",
    "\n",
    "births = pd.read_csv(\"nc.csv\")\n",
    "display(births)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Joint plot between weeks and weight\n",
    "sns.jointplot(data=births,x='weeks',y='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using the sample size we decide on\n",
    "(train, test) = sklearn.model_selection.train_test_split(births, test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model on the training set and plot the fit \n",
    "train_model = sm.ols(\"weight ~ weeks + I(weeks**2) + I(weeks**3)\", data=train).fit()\n",
    "plt.scatter(train.weeks,train.weight)\n",
    "T = pd.DataFrame({'weeks':np.arange(20,46)})\n",
    "T['weight']=train_model.predict(exog=T)\n",
    "plt.plot(T.weeks,T.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Bootstrap function that records the fitted models \n",
    "def BootstrapFit(data):\n",
    "    numboot = 1000\n",
    "    n = len(data)\n",
    "    bsFit = [None]*numboot    \n",
    "    for i in range(numboot):\n",
    "        d = data.sample(n, replace=True)\n",
    "        bsFit[i] = sm.ols(\"weight ~ weeks + I(weeks**2) + I(weeks**3)\", data=d).fit()\n",
    "    return bsFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 Bootstrap fits\n",
    "bsFit = BootstrapFit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Extract the parameters for the 1000 Boostrap fits.\n",
    "#  Also generate the predictions for the 1000 Bootstrap fits \n",
    "YP = np.zeros((len(bsFit),len(T.weeks)))\n",
    "theta = np.zeros((len(bsFit),4))\n",
    "for i in range(len(bsFit)):\n",
    "    YP[i,:]=bsFit[i].predict(exog=T)\n",
    "    theta[i,:]=bsFit[i].params.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a joint plot of two parameters \n",
    "sns.jointplot(x=theta[:,0],y=theta[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data frame from the parameter estimates \n",
    "B=pd.DataFrame({'theta0':theta[:,0],'theta1':theta[:,1],'theta2':theta[:,2],'theta3':theta[:,3],})\n",
    "# Produce a pair plot of all co-dependencies \n",
    "sns.pairplot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 20 of the bootstrapped predictions \n",
    "for i in range(1000):\n",
    "    plt.plot(T.weeks,YP[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluculate upper and lower confidence bounds for prediction \n",
    "# From Bootstrapped means \n",
    "upper=np.quantile(YP,0.975,axis=0)\n",
    "lower=np.quantile(YP,0.025,axis=0)\n",
    "plt.plot(T.weeks,T.weight)\n",
    "plt.plot(T.weeks,lower,'k:')\n",
    "plt.plot(T.weeks,upper,'k:')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
